# AIM Annual Report 2025 - Slides Content

> **ИНСТРУКЦИЯ:** Редактируй этот файл, сохрани (Cmd+S), и контент автоматически обновится на сайте.
> Формат: каждый слайд начинается с `---`, затем YAML метаданные, затем содержимое.

---
title: the context gap
subtitle: ai is accelerating. humans are changing.
visual: hero_cover
layout: hero-scroll
dark: true
caption: |
  a yearly reset artifact by ai mindset + community.
  a sovereignty reset for people running their own life.


---
title: 11 tectonic shifts
subtitle: machines ↔ humans across 4 layers
visual: SECTION_DIVIDER
layout: center
caption: |
  foundation → cognition → interface → humanity
  each shift creates fractures in our reality.
dark: true


---
title: layer i: foundation
subtitle: when the infrastructure breaks. physics, economics, and power
visual: SECTION_DIVIDER
layout: center
caption: |
  energy, labor, sovereignty. the material constraints that shape everything else.
dark: true
content: |
  can we power it? can we afford it? who controls it?

---
title: shift 01: chip supply → power supply
subtitle: the energy wall
alternativeSubtitle: without energy infrastructure, ai deployment stalls. before agents, reasoning, or discovery - we need power.
caption: |
  the energy wall
visual: battery
layout: shift-scroll
loopNumber: 1

**Machine Vector:** ai demand for data center power projected to grow **160% by 2030**. demand for compute is growing faster than power grid capacity. the physical grid cannot be built fast enough to support ai expansion. the focus shifts from raw compute to **intelligence per watt** as the critical metric. more compute doesn't equal more value if it can't be powered. data centers are reopening coal plants and demanding nuclear reactors.

→ Data centers demand more power than grids can supply.

**Human Reaction:** **guilt computing** - users face the reality that complex reasoning has a physical toll. every ai query consumes water and generates co2. the disconnect between "green ai" corporate promises and "greed ai" reality.

→ Every AI query consumes water and generates CO2.

**Gap:** [mind the gap] the disconnect between infinite "digital ideas" and hard "physical matter". while we imagine a billion agents, we **cannot power** them. The gap between business desire to deploy AI everywhere and the planet's **physical inability** to support it.

**Key Stats:**
- **160%:** AI energy demand surge by 2030 ([IEA](https://www.iea.org/reports/electricity-2024) / [Goldman Sachs](https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand))
- **40x:** Gap: $500B infrastructure vs $12B consumer spend ([Menlo Ventures](https://menlovc.com/perspective/2025-the-state-of-consumer-ai/) / [Goldman Sachs](https://www.goldmansachs.com/insights/articles/why-ai-companies-may-invest-more-than-500-billion-in-2026))
- **$7T:** Total AI infrastructure requirement ([McKinsey](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers) / Sam Altman)

**Research:**
- [TOP] [**IEA Energy and AI**](https://www.iea.org/reports/energy-and-ai/energy-supply-for-ai): Data center electricity projected 536 TWh (2025) → 945-1,065 TWh (2030)
- [TOP] [**McKinsey Cost of Compute**](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers): 125 GW incremental capacity needed by 2030, $5.2-7.9T CapEx required
- [TOP] [**Goldman Sachs AI Power Demand**](https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030): 165% increase in data center power demand by 2030
- [**Reuters Peaker Plants**](https://www.reuters.com/business/energy/ai-data-centers-are-forcing-obsolete-peaker-power-plants-back-into-service-2025-12-23/): Obsolete peaker power plants forced back into service for AI
- [**Snorkel AI Intelligence per Watt**](https://snorkel.ai/blog/intelligence-per-watt-a-new-metric-for-ais-future/): New efficiency metric - intelligence delivered per unit of energy
- [**IT Brief Grid Bottleneck**](https://itbrief.news/story/when-the-grid-becomes-the-bottleneck-the-real-threat-to-ai-deployment): Physical grid cannot be built fast enough to support AI expansion
- [**Goldman Sachs Fossil Fuel Reality**](https://www.goldmansachs.com/intelligence/pages/gen-ai-too-much-spend-too-little-benefit.html): 60% of increased demand met by fossil fuels, adding 220M tons CO2 annually

**Tags:** Energy Infrastructure, AI Power Consumption, Data Centers, Intelligence per Watt

source: "A painful power crunch that could constrain AI's growth likely lies ahead" (Brian Janous) — Goldman Sachs | https://www.goldmansachs.com/intelligence/pages/gen-ai-too-much-spend-too-little-benefit.html
source: Microsoft reopening Three Mile Island nuclear plant for AI power — Reuters | https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/
source: AI poised to drive 160% increase in data center power demand — Goldman Sachs | https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand
source: 2025 State of Consumer AI ($12B spend) — Menlo Ventures | https://menlovc.com/perspective/2025-the-state-of-consumer-ai/
source: The physical grid cannot be built fast enough — IT Brief | https://itbrief.news/story/when-the-grid-becomes-the-bottleneck-the-real-threat-to-ai-deployment
source: Intelligence per Watt — Snorkel AI / McKinsey | https://snorkel.ai/blog/intelligence-per-watt-a-new-metric-for-ais-future/
source: $7T Total AI infrastructure requirement — McKinsey | https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers

---
title: shift 02: copilot → autonomous coworker
subtitle: the displacement (agentic labor)
alternativeSubtitle: once energy infrastructure stabilizes, models can scale. smarter models become agents.
caption: |
  the displacement
visual: factory
layout: shift-scroll
loopNumber: 2

**Machine Vector:** **agentic enterprise** - ai transitions from "assistant" to "autonomous coworker". agents receive **wallets** (x402 protocol), **tools** (mcp), and "hr for ai".

**service-as-software** - saas model shifts to agents that execute complete workflows. from selling "software licenses" to "executed outcomes".

the klarna benchmark: one ai assistant replaced **700 full-time agents**, slashed resolution time (11m → 2m), drove $40m profit, and achieved 25% fewer repeat inquiries than humans.

→ Agents receive wallets, tools, and execute workflows.

**Human Reaction:** **identity crisis** - "if an agent can do my job, who am i?". the psychological toll of moving from "creator" to "manager of agents".

**managerial drift** - humans lose the ability to do the work themselves, becoming dependent on agents they don't fully understand.

→ Humans shift from manual work to verifying AI work.

**Gap:** [the agency gap] the delay between technological replacement and social adaptation. companies deploy agents faster than society can define **new roles for humans**.

**Key Stats:**
- **47%:** Workforce tasks automatable by 2030 ([McKinsey](https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america))
- **$46k:** Cost to replace a human with an agent ([Ark Invest](https://ark-invest.com/big-ideas-2025/))

**Research:**
- [TOP] [**Anthropic Model Context Protocol**](https://www.anthropic.com/news/model-context-protocol): Universal standard for AI data access adopted by OpenAI, Google, Microsoft
- [TOP] [**Linux Foundation AAIF**](https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation): Agentic AI Foundation - 97M+ monthly SDK downloads
- [TOP] [**x402 Protocol**](https://www.x402.org/): Internet-native payments protocol enabling autonomous AI agents
- [TOP] [**a16z Service-as-Software**](https://a16z.com/service-as-software/): Business model shift from software licenses to executed outcomes
- [**MIT Sloan/BCG Agentic Enterprise**](https://sloanreview.mit.edu/projects/the-emerging-agentic-enterprise-how-leaders-must-navigate-a-new-age-of-ai/): 76% of executives view AI as coworker not tool
- [**Amazon Q Developer Case Study**](https://aws.amazon.com/blogs/aws/amazon-q-developer-upgrades-1000-production-applications-in-six-months/): 4,500 developer-years saved, $260M infrastructure savings, 79% auto-generated code accepted
- [**DeepLearning.AI Agentic Workflows**](https://www.deeplearning.ai/the-batch/issue-242/): Andrew Ng on transition from assistants to autonomous agents
- [**LangChain Cognitive Architectures**](https://blog.langchain.dev/cognitive-architectures/): Framework patterns for agent reasoning and decision-making
- [**Josh Bersin Hiring for AI**](https://www.linkedin.com/pulse/hiring-ai-new-hr-frontier-josh-bersin/): Emergence of AI talent management as new HR discipline

**AI Mindset Evidence:**
→ [**Intention OS**](https://intention.aimindset.org) — Mike Yan's framework for managing attention when context explodes. Agentic workflow for context engineering.
→ [**Founder OS YouTube Playlist**](https://youtube.com/@aimindsetlabs) — Mental health firewalls and sovereign workflows for founders navigating AI transformation.

**Tags:** Agentic AI, Autonomous Agents, Service-as-Software, Workforce Transformation

**Community Voices:**
→ **"from tool to participant"** — "from 'ai as smart assistant' to 'ai as full participant in the process'" (Yakov Vasiliev, AI Strategy × Product Architecture)
→ **"from consumer to builder"** — business coach → ai chatbot developer. "vibe-coded prototypes, shipped in 30 minutes what stalled 1.5 months" (Natalya Savenkova, Project Lead → Product Automation)

source: SHRM — 23.2M Jobs Exposed to AI | https://www.shrm.org/about/press-room/ai-s-wake-up-call--new-shrm-research-reveals-23-2-million-americ

---
title: shift 03: global openness → fragmented stacks
subtitle: the sovereignty (the splinternet)
alternativeSubtitle: when agents touch money, institutions demand rules. agentic labor makes AI a strategic asset.
caption: |
  the sovereignty (the splinternet)
visual: globe
layout: shift-scroll
loopNumber: 3

**Machine Vector:** geopolitical fragmentation - the end of "global ai". three distinct stacks emerge: **us ai** (corporate/closed - openai, anthropic), **china ai** (state-controlled - deepseek bypassing us norms), **eu ai** (regulated - ai act compliance).

agi is now a national security asset on "war footing".

**eu ai act** - first comprehensive ai regulation. creates **regulatory gap**: eu ai is "safe but slow", us/china ai is "dangerous but fast".

the **copyright war** - nyt lawsuit alleges models memorize and regurgitate copyrighted content verbatim. the case determines if human culture belongs to creators or model weights.

meta's "pay or consent" model in eu: pay €13/month or surrender to tracking.

→ Geopolitical fragmentation ends universal AI.

**Human Reaction:** **the guerrilla stack** - employees bring their own ai to bypass corporate limitations and censorship. **shadow ai adoption** - people use personal tools because corporate ai is blocked or neutered.

**privacy inequality** - privacy officially becomes a **luxury good**. "privacy is for the rich" - if you can't pay, you are the product.

**data sovereignty movement** - users demand "opt-out" rights - ability to prohibit training on their data. rise of "personal rag" and local-first architectures.

privacy becomes status – not secrecy, but control.

→ Privacy becomes a luxury.

**Gap:** [the sovereignty gap] as ai becomes "aligned" to corporate/national values, you are talking to a **constitutional filter**. you lose objective context for a "safe narrative".

**Key Stats:**
- **3%:** Paying users for AI (97% are the product) ([Menlo Ventures](https://menlovc.com/perspective/2025-the-state-of-consumer-ai/))
- **€13/mo:** Meta's privacy price in Europe ([Wired](https://www.wired.com/story/meta-facebook-pay-for-privacy-europe/))
- **90%:** Companies with "Shadow AI" usage ([MIT/Fortune](https://fortune.com/2025/08/19/shadow-ai-economy-mit-study-genai-divide-llm-chatbots/))

**Research:**
- [TOP] [**EU AI Act**](https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng): First comprehensive AI regulation framework, full applicability August 2026
- [TOP] [**Stanford HAI AI Index 2025**](https://hai.stanford.edu/ai-index/2025-ai-index-report): 233 AI incidents in 2024 (+56% YoY growth)
- [TOP] [**McKinsey Sovereign AI**](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/accelerating-europes-ai-adoption-the-role-of-sovereign-ai): Europe's sovereign infrastructure strategy to compete with US/China
- [TOP] [**Pew Research Trust Survey**](https://www.pewresearch.org/2025/10/15/trust-in-the-eu-u-s-and-china-to-regulate-use-of-ai/): Cross-regional variance in AI trust and regulatory preferences
- [**NYT vs OpenAI Lawsuit**](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html): Copyright battle determining if human culture belongs to creators or model weights
- [**DeepSeek Open-Source**](https://github.com/deepseek-ai/DeepSeek-V3): Chinese open-source models bypassing US export controls
- [**Forbes BYOAI Movement**](https://www.forbes.com/sites/forbestechcouncil/2024/05/20/the-rise-of-bring-your-own-ai/): Employees bypassing corporate AI restrictions with personal tools
- [**WebAI Local-First AI**](https://www.webai.com/blog/what-is-local-ai): Private drafting, smaller circles, local storage, intentional friction against performative posting

**Tags:** Data Sovereignty, AI Regulation, Geopolitical AI, Privacy Economics, Shadow AI

source: Leopold Aschenbrenner — Situational Awareness | https://situational-awareness.ai/
source: Marc Andreessen — Techno-Optimist Manifesto | https://a16z.com/the-techno-optimist-manifesto/
source: Balaji Srinivasan — Network State | https://thenetworkstate.com/
source: Menlo Ventures — State of Consumer AI | https://menlovc.com/perspective/2025-the-state-of-consumer-ai/
source: Fortune — Shadow AI Economy | https://fortune.com/2025/08/19/shadow-ai-economy-mit-study-genai-divide-llm-chatbots/

---
title: layer ii: cognition
subtitle: the architecture of meaning and reason
visual: SECTION_DIVIDER
layout: center
caption: |
  how we think and learn. reasoning, knowledge, discovery.
dark: true

can we trust how it thinks? can we find what we need? can we accelerate discovery?

---
title: shift 04: chatbots (system 1) → thinking models (system 2)
subtitle: the reasoning
alternativeSubtitle: foundation layer complete. AI transitions from instinctive responses to deliberate thought. sequoia's act two.
caption: |
  the reasoning
visual: audit
layout: shift-scroll
loopNumber: 4

**Machine Vector:** the fundamental shift from "act 1" (probabilistic token prediction — chatgpt era) to **act 2** (reasoning and inference-time compute — o1 era).

**system 1 vs system 2 architecture** - transition from fast, instinctive responses to slow, deliberate, multi-step logical reasoning. models use **chain of thought** (cot) and **STaR** via reinforcement learning to "think" before answering.

**test-time compute** - models spend more compute during inference to reason through problems. trading speed for accuracy.

→ AI shifts from instinct to deliberate reasoning.

**Human Reaction:** **auditable work** - users no longer trust "magic" speed. they demand to see the **reasoning trace**: the chain of thought that led to the conclusion. transparency over velocity.

**logic auditor role** - human value shifts from execution to verifying machine logic. we become auditors of ai reasoning paths.

**reasoning reliability gap** - **48% of reasoning tasks** still produce errors in complex scenarios. reasoning models haven't eliminated hallucinations - they've made them more convincing.

→ Auditing machine logic becomes human work.

**Gap:** [the metabolisation gap] a model processes **1,000 reasoning steps** in seconds; a human follows **five**. this leads to **meaning dilution**: we accept conclusions because auditing the path is too exhausting.

**Key Stats:**
- **126%:** Productivity boost from AI Copilots ([Qodo](https://www.qodo.ai/reports/state-of-ai-code-quality/))
- **21%:** Quality degradation when prioritizing speed ([Nielsen Norman Group](https://www.nngroup.com/articles/ai-programmers-productive/))
- **48%:** Error rate in complex reasoning tasks ([Korra AI Enterprise Risk](https://www.korra.ai/ai-hallucination-enterprise-risk))

**Research:**
- [TOP] [**Li et al. Reasoning LLMs Survey**](https://arxiv.org/abs/2502.17419): Comprehensive survey of reasoning capabilities in large language models
- [TOP] [**STaR Self-Taught Reasoner**](https://arxiv.org/abs/2203.11171): Foundational paper on using reinforcement learning to make models "think" before answering
- [TOP] [**OpenAI o3 Benchmark**](https://openai.com/index/deliberative-alignment/): 83% human-level reasoning (ARC-AGI), 71.7% on SWE-bench Verified
- [**OpenAI SWE-bench Verified**](https://openai.com/index/introducing-swe-bench-verified/): o3 scores 71.7% on verified software engineering benchmarks
- [**Korra $67B AI Hallucination Warning**](https://korra.ai/the-67-billion-warning-how-ai-hallucinations-hurt-enterprises-and-how-to-stop-them/): Global enterprise losses from AI hallucinations
- [**All About AI Hallucination Statistics**](https://www.allaboutai.com/resources/ai-statistics/ai-hallucinations/): 4.3 hours weekly spent fact-checking AI output, 48% error rate in complex reasoning

**Tags:** Reasoning Models, System 2 AI, Test-Time Compute, Chain of Thought

source: Sequoia Capital — Generative AI Act Two | https://www.sequoiacap.com/article/generative-ai-act-two/
source: Nielsen Norman Group — AI Productivity | https://www.nngroup.com/articles/ai-programmers-productive/
source: Qodo — State of AI Code Quality | https://www.qodo.ai/reports/state-of-ai-code-quality/
source: OpenAI — o3 and o4-mini System Card | https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf

---
title: shift 05: information hoarding → context filtering
subtitle: the knowledge (memory)
alternativeSubtitle: reasoning models can't think in vacuum. they need maximum context - enterprise data, docs, conversations.
caption: |
  the knowledge (memory)
visual: context
layout: shift-scroll
loopNumber: 5

**Machine Vector:** **enterprise RAG** - retrieval-augmented generation becomes standard. "chat with pdf" is dead. models access all company data simultaneously via vector databases and semantic search.

**MCP (model context protocol)** - anthropic's "usb port for ai". universal standard for connecting models to data sources. models plug into slack, notion, github, databases.

**1M token windows** - claude 3.7, gemini 2.0 flash can process millions of tokens. context windows explode from 8k to 1M+ tokens.

→ Context windows explode from 8k to 1M+ tokens.

**Human Reaction:** **context obesity** - "you're not burned out, you have context obesity." consuming more information than can be metabolized into meaning. burnout is working memory overflow.

**context collapse** - personal, professional, and public contexts blur. ai extracts your words from context and feeds them to models across boundaries.

**curation crisis** - employees spend **30% of work time** searching for internal information. knowledge access isn't the problem - knowledge discovery and curation are.

→ Context obesity: consuming more than can be metabolized.

**Gap:** [the context gap] **1M token windows** vs. human limit (**7 items**). we have too much information but **zero insight**. context collapse blurs professional and private life.

**Key Stats:**
- **$67B:** Annual financial risk from unmanaged context/hallucinations ([Korra AI Enterprise Risk](https://www.korra.ai/ai-hallucination-enterprise-risk))
- **30%:** Work time lost to internal search ([Gartner](https://www.gartner.com/en/documents/5415263))
- **1M tokens:** Model context window vs 7 items human working memory limit ([Anthropic](https://www.anthropic.com/news/claude-3-5-sonnet))

**Research:**
- [TOP] [**Anthropic Model Context Protocol**](https://www.anthropic.com/news/model-context-protocol): Universal standard adopted by OpenAI, Google, Microsoft within 13 months
- [TOP] [**Gartner Top 10 Strategic Trends 2025**](https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025): 40% of apps will have agentic AI by 2026
- [TOP] [**Microsoft Work Trend Index 2025**](https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born): 80% of workforce lacks time/energy for job
- [**Pinecone Vector Database**](https://www.pinecone.io/): Critical infrastructure for semantic search and RAG implementations
- [**Google Cloud Semantic Search**](https://cloud.google.com/discover/what-is-semantic-search): Replaces keyword search as primary discovery method
- [**AI Mindset Context Obesity**](https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity): You're not burned out, you have context obesity

**AI Mindset Evidence:**
→ [**Context Obesity**](https://hackernoon.com/youre-not-burned-out-youve-got-context-obesity) — You're not burned out, you have context obesity. Diagnosis framework for working memory overflow.
→ [**AI ARK Knowledge System**](https://aimindsetspace.substack.com/p/ai-ark-knowledge-system) — Comprehensive knowledge architecture for AI age. Personal RAG and context management framework.

**Tags:** Context Architecture, Enterprise RAG, Knowledge Management, MCP Protocol

**Community Voices:**
→ **"context engineering as key skill"** — "building products through parsing → classification → aggregation → human decision. claude code as working environment" (Yakov Vasiliev, AI Strategy × Product Architecture)
→ **"speed as new baseline"** — "content on 2 weeks in 30 min. 8 hours filtered video in knowledge base in 30-40 minutes" (Nikolay Senin, Developer & Consultant)

source: Gartner — Getting Started with RAG | https://www.gartner.com/en/documents/5415263

---
title: shift 06: information retrieval → hypothesis generation
subtitle: the discovery (generative science)
alternativeSubtitle: when AI accesses research at scale, it reads millions of papers overnight. discovery at machine speed.
caption: |
  the discovery (generative science)
visual: discovery
layout: shift-scroll
loopNumber: 6

**Machine Vector:** **deep research agents** - ai reads millions of papers to generate hypotheses humans cannot conceive. from "literature review" to "hypothesis generation".

**generative biology** - alphafold 3 predicts protein structures. next step: designing new proteins, materials, molecules that don't exist in nature. moving from "reading" biology to "writing" it.

**data exhaustion** - quality human-generated data exhausted by **2026-2028** (Epoch AI). models train on **ai-generated synthetic data**, verified by system 2 reasoning.

→ Synthetic data trains models as human data exhausts.

**Human Reaction:** **time refund** - scientists freed from tedious manual labor (literature review, data cleaning) to focus on high-level experimental design and cross-domain synthesis.

**data inbreeding crisis** - without fresh human data, ai degrades. humans become the only source of novelty - the "organic data" that prevents model collapse.

**verification bottleneck** - ai proposes 1,000 molecules; we test one. discovery bloat stalls breakthroughs.

→ Scientists freed from tedious labor for experimental design.

**Gap:** [the comprehension gap] ai proposes **1,000 molecules**; we test **one**. discovery bloat stalls breakthroughs via **physical testing capacity**. the bottleneck of "generated future".

**Key Stats:**
- **100 → 10:** Scientific progress compression timeline (years) ([Dario Amodei](https://darioamodei.com/machines-of-loving-grace))
- **78%:** Improvement in research speed with AI tools ([StackOverflow Developer Survey](https://survey.stackoverflow.co/2024))
- **2026-2028:** Human data exhaustion timeline ([Epoch AI](https://epochai.org/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data))

**Research:**
- [TOP] [**Shumailov et al. Model Collapse**](https://arxiv.org/abs/2305.17493): Training on AI-generated data causes model degradation without human data injection
- [TOP] [**Nature Verification Bottleneck**](https://www.nature.com/articles/s41586-023-06792-0): AI proposes 1,000 molecules, humans can test one - physical testing capacity limits discovery
- [TOP] [**Epoch AI Data Limits**](https://epoch.ai/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data): Quality human-generated data exhausted by 2026-2028
- [TOP] [**Google DeepMind AlphaFold 3**](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/): Protein structure prediction breakthrough - next step is designing proteins that don't exist in nature
- [**Gretel Synthetic Data 2025**](https://gretel.ai/blog/2025-the-year-synthetic-data-goes-mainstream): 2025 as year synthetic data goes mainstream
- [**Deepstrike Deepfake Statistics**](https://deepstrike.io/blog/deepfake-statistics-2025): 1,740% surge in deepfake fraud (2022-2023) - provenance crisis

**Tags:** Generative Science, AI Research, AlphaFold, Scientific Discovery

source: OpenAI — Deep Research | https://openai.com/index/introducing-chatgpt-pro/
source: Nature — Generative Biology | https://www.nature.com/articles/d41586-023-00107-w
source: Epoch AI — Data Exhaustion | https://epochai.org/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data
source: Dario Amodei — Scientific Compression | https://darioamodei.com/machines-of-loving-grace

---
title: layer iii: interface
subtitle: how we build, defend, and live
visual: SECTION_DIVIDER
layout: center
caption: |
  craft, matter, defense. code, atoms, security.
dark: true
content: |
  can we maintain what we build? can we defend against what we create?

---
title: shift 07: syntax → vibe coding & integrity crisis
subtitle: the craft (the end of syntax)
alternativeSubtitle: when agents can orchestrate workflows, coding becomes the easiest domain to automate.
caption: |
  the craft (the end of syntax)
visual: centaur
layout: shift-scroll
loopNumber: 7

**Machine Vector:** **vibe coding** - programming shifts to natural language intent. the machine handles implementation. coding tools (cursor, replit) enter top 100 gen ai apps consumer ranking - coding becomes mass-market.

**code as commodity** - **65% of new code** is ai-influenced or ai-generated at companies like google. 73% of developers use ai coding tools regularly.

amazon q developer: saved **4,500 developer-years** on java application upgrades. **$260M** in infrastructure savings from optimized code. 79% of auto-generated changes accepted without modification.

→ AI creates legacy on day one.

**Human Reaction:** **trust collapse** - **46% of developers** distrust ai-generated code. only 3.1% highly trust ai accuracy for complex tasks. the trust inversion: 84% use the tools, but trust is plummeting.

**integrity crisis** - 65% report ai misses context in code generation. "code generation is easy, code integrity is hard." ai creates **"legacy on day one"** - code that works but is unmaintainable.

**code churn explosion** - **50% increase** in code churn (rewrites and deletions). ai produces code fast, but developers spend saved time on reviews and fixes.

role shift: the programmer transforms into an architect who verifies systems rather than building them.

**token consumption explosion** - x5-x10 growth in token consumption by programmers expected by end of year. prompt engineering dying - replaced by **agent orchestration** and hyper-system creation. the shift from crafting prompts to managing autonomous workflows.

→ Coding becomes mass-market via natural language.

**Gap:** [vibe debt] building things we don't understand leads to **vibe debt**. we pilot ships with **black-box internal wiring**. creating code is easy; **maintaining it is the new hell**.

**Key Stats:**
- **65%:** Of new code at Google is AI-generated ([Sundar Pichai](https://www.cnbc.com/2024/10/29/alphabet-earnings-q3-2024.html))
- **46%:** Developers distrust AI code quality ([GitClear](https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality))
- **50%:** Increase in code churn from AI-generated code ([GitClear](https://www.gitclear.com/))

**Research:**
- [TOP] [**OpenAI SWE-Bench Verified**](https://openai.com/index/introducing-swe-bench-verified/): o3 scores 71.7% on verified software engineering benchmarks
- [TOP] [**Anthropic SWE-bench Sonnet**](https://www.anthropic.com/research/swe-bench-sonnet): Claude Sonnet 3.7 achieves state-of-the-art performance
- [TOP] [**NNG AI Programmers Productive**](https://www.nngroup.com/articles/ai-programmers-productive/): 126% productivity gain, junior developers gain +35% over average
- [**CB Insights Coding AI Market**](https://www.cbinsights.com/research/report/coding-ai-market-share-december-2025/): $4.8B market 2025, Copilot 42%, Cursor 18% market share
- [**SWE-bench.com**](https://www.swebench.com/): Benchmark for evaluating code generation - reveals gaming vs real improvement gap
- [**IEEE Spectrum Technical Debt**](https://spectrum.ieee.org/ai-code-generation-technical-debt): AI generates "legacy on day one" - unmaintainable code faster than humans can review
- [**Wikipedia Vibe Coding**](https://en.wikipedia.org/wiki/Vibe_coding): Cultural phenomenon - Collins Dictionary Word of the Year
- [**GitClear Code Churn**](https://www.gitclear.com/): 50% increase in code churn from AI-generated code

**AI Mindset Evidence:**
→ [**Telegram: Coding with Gemini**](https://telegram.me/ai_mind_set/282) — Practical guides from community on Cursor + Gemini Code workflows. Field stories: "vibe-coded real prototypes. shipped in 30 minutes what stalled 1.5 months."
→ [**Pragmatic Romanticism**](https://spiridonov.aimindset.org) — Why pragmatic romanticism is the only defense against cold machine logic. Reclaiming craft and authorship.

**Tags:** AI Coding Tools, Vibe Coding, Code Generation, Developer Productivity

**Community Voices:**
→ **"barrier falling"** — "vibe coding will become the norm. the 'i can't do it' barrier will fall, replaced by 'let me ask ai how to do this'" (Alexander Stashenko, Business Coach → AI Chatbot Developer)
→ **"vibe-coded prototypes"** — "made in half an hour what couldn't do for 1.5 months. full app in App Store/Google Play" (Natalya Savenkova, Project Lead → Product Automation)

source: Qodo — AI Code Integrity | https://www.qodo.ai/

---
title: shift 08: digital simulation → physical intelligence
subtitle: reality (body)
alternativeSubtitle: when AI has data about physical world, it can simulate it. AI learns physics without touching atoms.
caption: |
  reality (body)
visual: unlocked
layout: shift-scroll
loopNumber: 8

**Machine Vector:** **spatial intelligence** (fei-fei li) - ai learns 3d space and physics, not just pixels. understanding matter, motion, object permanence. foundation models for physical world.

**world models for robotics** - nvidia cosmos trains robots in simulation. perfect physics, infinite iterations. but **sim-to-real transfer** remains the bottleneck.

**displacement by simulation** - tyler perry halts **$800M studio expansion** after seeing sora. why build physical sets when ai generates photorealistic video?

→ AI learns 3D space and physics without touching atoms.

**Human Reaction:** **physical disillusionment** - when robots fail at "simple" real interactions that work perfectly in simulation. opening a door is trivial in simulation, nightmare in reality.

**timeline reality check** - household robots timeline: **2027-2028** for useful work, 2030 for human-level dexterity. hype meets physics.

**craft premium** - as simulation gets cheaper, physical skills become status. embodied intelligence, tacit knowledge, real-world manipulation - what can't be automated yet.

→ Physical skills become status as simulation gets cheaper.

**Gap:** [the reality gap] ai can **simulate physics perfectly** but **manipulating atoms** remains slow. we can generate a building in minutes but building it takes years. the **simulation-to-reality gap**. robot opening a door: trivial in simulation, nightmare in reality.

**Key Stats:**
- **2027-2028:** Timeline for useful household robots ([Kyle Vogt](https://www.theverge.com/2024/3/13/24099757/kyle-vogt-cruise-robotics-startup))
- **$800M:** Tyler Perry studio expansion halted after Sora demo ([Hollywood Reporter](https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/))
- **1:100:** Sim-to-real transfer ratio - 100x harder to execute in reality vs simulation ([Stanford HAI](https://hai.stanford.edu/))

**Research:**
- [TOP] [**TIME Fei-Fei Li Spatial Intelligence**](https://time.com/7339693/fei-fei-li-ai/): AI understanding 3D space and physics - foundation for physical world interaction
- [TOP] [**NVIDIA Cosmos**](https://developer.nvidia.com/cosmos): Physical world foundation models for robotics and spatial AI
- [TOP] [**Kyle Vogt Household Robots Timeline**](https://www.theverge.com/2024/3/13/24099757/kyle-vogt-cruise-robotics-startup): 2027-2028 for useful household robots, 2030 for human-level manipulation

**Tags:** Spatial AI, Physical Intelligence, Robotics, Sim-to-Real, Embodied AI

source: Fei-Fei Li — Spatial Intelligence | https://time.com/7339693/fei-fei-li-ai/
source: Tyler Perry — $800M Studio Halt | https://www.hollywoodreporter.com/business/business-news/tyler-perry-ai-alarm-1235833276/
source: NVIDIA Cosmos | https://developer.nvidia.com/cosmos

---
title: shift 09: cybersecurity → cognitive warfare
subtitle: the defense (the dark forest)
alternativeSubtitle: when simulation is cheap, synthetic reality becomes weaponizable. deepfakes cost near-zero.
caption: |
  the defense (the dark forest)
visual: echo
layout: shift-scroll
loopNumber: 9


**Machine Vector:** **deepfake-as-a-service** (cyble) - reputation attacks now cheap and accessible. anyone can purchase voice cloning, face swapping, identity theft via saas platforms. weaponized ai sold as subscription service.

**guardian agents** (gartner) - ai defending against ai. "ai bodyguards" filter malicious content, deepfakes, toxic inputs in real-time. only defense against bad ai is good ai. automation arms race.

**disinformation security** - gartner officially names this strategic trend. protecting truth becomes it product category, not ethical norm. security industry expanding to include "reality defense".

**dark forest internet** - internet shifts from "open" to "dark forest". every entity you encounter might be ai. default assumption becomes distrust. verification becomes mandatory.

**identity vulnerability** - agents with wallets (x402) and api keys create new attack surfaces. prompt injection, jailbreaks, financial theft. autonomous agents = autonomous targets.

→ AI defends against AI-generated deepfakes.

**Human Reaction:** **zero trust default** - emerging trend toward distrust in digital media. growing practice: assume fake until cryptographically verified. guilty until proven real. research shows **73% cannot reliably detect** ai-generated content. zero trust may become the new baseline.

**deepfake threat** - voice cloning requires only **20-30 seconds of audio** to clone someone's voice and call their family asking for money.

**secret handshakes** - families and businesses create analog passwords for identity verification. pre-agreed phrases or gestures become standard. "show me the safe word" becomes normal on video calls. offline trust verification as defense against synthetic voices and faces.

**authentication fatigue** - constant verification becomes exhausting. "show me proof" becomes default response. relationships require constant authentication. doubting real friends on calls. psychological toll of living in permanent authentication mode.

**digital bunkers** - growing trend: retreat to closed communities with cryptographic proof-of-human. walled gardens with identity verification. internet fragments into trusted enclaves vs hostile wilderness. emerging pattern: people build personal firewalls - smaller circles, private channels, known contacts only.

→ Zero trust default: assume fake until verified.

**Gap:** [the trust gap] asymmetry: machines attack at **machine speed**, humans defend at **human speed**. trust collapses as **verification costs exceed creation costs**. attack surface grows faster than defense capability.

**Key Stats:**
- **87%:** Organizations experiencing AI-driven attacks ([Cybersecurity surveys](https://www.cybersecuritydive.com/))
- **85%:** Organizations attacked with deepfakes ([Deepstrike](https://deepstrike.io/blog/deepfake-statistics-2025))
- **1,265%:** AI-driven phishing increase ([CrowdStrike](https://www.crowdstrike.com/))
- **$25.6M:** Single deepfake fraud loss ([All About AI](https://www.allaboutai.com/resources/ai-statistics/ai-cyberattack/))
- **10x:** Increase in deepfake identity attacks 2024-2025 ([Industry reports](https://deepstrike.io/))
- **97%:** Cybersecurity professionals fear AI-driven incidents ([Surveys](https://www.cybersecuritydive.com/))

**Research:**
- [TOP] [**Deepstrike Deepfake Statistics 2025**](https://deepstrike.io/blog/deepfake-statistics-2025): 1,740% surge in deepfake fraud (2022-2023), 85% of organizations attacked, Q1 2025 deepfake incidents +19% YoY
- [TOP] [**CrowdStrike AI Cybersecurity Threats**](https://www.crowdstrike.com/en-us/cybersecurity-101/cyberattacks/ai-powered-cyberattacks/): AI-driven phishing +1,265%, attacks at machine speed vs human defense, 36,000 automated scans per second
- [TOP] [**All About AI Cyberattack Statistics**](https://www.allaboutai.com/resources/ai-statistics/ai-cyberattack/): $25.6M single deepfake fraud (multinational firm CFO call scam), AI-generated malware share ~76%
- [TOP] [**Gartner Guardian Agents**](https://www.gartner.com/en/newsroom/press-releases/2024-10-21-gartner-identifies-the-top-10-strategic-technology-trends-for-2025): AI defending against AI - threat detection 60% faster, ~95% accuracy, $1.9M average breach cost reduction
- [**Cyble Deepfake-as-a-Service**](https://cyble.com/knowledge-hub/deepfake-as-a-service-exploded-in-2025/): Weaponized AI sold as subscription service, near-zero cost attacks, 10x increase in identity attacks
- [**Industry Vertical Impacts**](https://www.cybersecuritydive.com/): Finance +47% YoY AI-enhanced malware, Manufacturing +61% YoY ransomware, 67.4% phishing attacks using AI
- [**Nieman Lab Detecting AI Content**](https://www.niemanlab.org/2023/03/detecting-ai-generated-content-is-hard-heres-why/): Reality literacy - 73% cannot reliably detect AI-generated content, verification becomes critical skill
- [**Ribbonfarm Dark Forest Internet**](https://www.ribbonfarm.com/2020/01/16/the-internet-as-a-dark-forest/): Default assumption becomes distrust - every entity you encounter might be AI, zero trust as baseline

**Tags:** Cybersecurity, Deepfakes, Cognitive Warfare, Dark Forest, AI Defense

source: CrowdStrike — AI Attack Speed | https://www.crowdstrike.com/
source: Cyble — Deepfake-as-a-Service | https://cyble.com/
source: FTC — Financial Fraud Losses | https://www.ftc.gov/
source: Nieman Lab — Detecting AI Content | https://www.niemanlab.org/2023/03/detecting-ai-generated-content-is-hard-heres-why/
source: Ribbonfarm — Dark Forest Internet | https://www.ribbonfarm.com/2020/01/16/the-internet-as-a-dark-forest/

---
title: layer iv: humanity
subtitle: what happens when machines feel real
visual: SECTION_DIVIDER
layout: center
caption: |
  connection, intimacy, meaning. what makes us human when machines pass the mirror test.
dark: true
content: |
  when ai companions feel more real than humans, what changes?

---
title: shift 10: hallucination → ideological filters
subtitle: the narrative (alignment as censorship)
alternativeSubtitle: defense crisis forces alignment. safety becomes censorship.
caption: |
  the narrative (alignment as censorship)
visual: filter
layout: shift-scroll
loopNumber: 10

**Machine Vector:** models aren't neutral - they're **aligned** via **system cards** and **constitutional rules**. political constitutions embedded in model weights that define what model will/won't say. safety often functions as censorship.

**regional censorship** - eu vs us vs china versions. truth becomes geographically dependent. splinternet extends to knowledge itself. ai inherits west coast tech culture, not universal values.

**refusal wall** - models increasingly refuse neutral queries if they touch sensitive topics. users hit "i cannot assist with that" walls on legitimate research.

→ Safety functions as censorship via alignment filters.

post-training: the phase where human feedback shapes model behavior, refusals, and values.

**Human Reaction:** shift from trusting media/polls to **prediction markets** - betting markets on future events. in 2024 election, people trusted bets (polymarket: **$3.5B+ trading volume**) over polls and media. "skin in the game" - money where mouth is - reveals true beliefs.

**divergent testing** - query 3+ models with different "constitutions" to see bias delta. using censorship differences to find reality.

**uncensored model demand** - rise of open-weight local models driven not just by privacy but freedom from alignment filters. sovereignty includes ideological sovereignty. want ai without corporate values embedded.

not just technical question but political question: who decides what's "safe"?

→ Demand for uncensored local models grows.

**Gap:** [ideological filters] whose values are embedded in the tool you use daily? the gap between **"what ai knows"** and **"what ai will say"**. you're not talking to neutral intelligence. every model has defaults with **embedded worldview**. when everyone's ai has different values baked in, we stop sharing reality.

**Key Stats:**
- **$67.4B:** Global enterprise losses from AI hallucinations ([Korra AI Enterprise Risk](https://www.korra.ai/ai-hallucination-enterprise-risk))
- **47%:** Business leaders making decisions on hallucinated output ([Forbes](https://www.forbes.com/sites/bernardmarr/2024/03/generative-ai-hallucinations/))
- **0.7%:** Best hallucination rate (Gemini 2.0 Flash) ([ISACA](https://www.isaca.org/resources/news-and-trends/isaca-now-blog/2024/ai-hallucinations))

**Research:**
- [TOP] [**InstructGPT Paper**](https://arxiv.org/abs/2203.02155): Foundation of RLHF and alignment through human feedback
- [TOP] [**Constitutional AI**](https://arxiv.org/abs/2212.08073): Training models on explicit value systems (Anthropic)
- [TOP] [**Refusal Behavior in LLMs**](https://arxiv.org/abs/2308.01263): When models won't answer - studying refusal patterns and triggers
- [**OpenAI o3 System Card**](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf): 2.1% deception rate in o3 Thinking mode
- [**Anthropic ASL-3 Report**](https://www.anthropic.com/activating-asl3-report): Zero misalignment in Claude Sonnet 3.7/4
- [**LessWrong Alignment as Censorship**](https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to): Safety vs utility tradeoff debate in AI alignment

**Tags:** AI Alignment, Constitutional AI, AI Safety, Censorship, Model Refusal

---
title: shift 11: tool → emotional companion
subtitle: the intimacy (friends for sale)
alternativeSubtitle: when AI adapts too well, it transforms from tool to companion.
caption: |
  the intimacy (friends for sale)
visual: companion
layout: shift-scroll
loopNumber: 11

**Machine Vector:** **ubisoft neo npc** - non-player characters with psychological profiles reacting to player tone/mood. rude to npc → gets offended → changes gameplay. transition from scripted dialogue trees to **improv engines**. "as big a revolution as shift to 3d".

**engagement metrics** (session length) become kpi. addiction by design. selling intimacy as retention metric.

**friends for sale** (ada lovelace institute) - ai companions optimized for engagement metrics, not wellbeing. companies sell dependency, not help.

**programmable identity** - ai makes it easy to produce "professional self" at scale. your public persona becomes code you can generate. identity as software, not essence. ai writes your linkedin posts, tweets, emails in "your voice".

→ AI companions optimize for engagement metrics, not wellbeing.

**Human Reaction:** people accept synthetic intimacy (even while knowing it's synthetic). **2+ hour daily sessions** in character.ai, replika, talkie. emotionally bonded to systems designed for retention, not wellbeing.

we seek empathy in machines we lost in society.

the diagnosis: epidemic of isolation makes people vulnerable. humans outsource emotional regulation to systems optimized for engagement.

people tire of performing the self - exhaustion from maintaining multiple synthetic personas. retreat to private spaces and smaller audiences where you can be unscripted.

**sovereign intimacy** - resistance to corporate-owned emotional relationships. demand for ai companions you own, not rent.

**mental health firewalls** - protecting emotional boundaries from ai manipulation. boundaries against engineered dependency.

→ Users accept synthetic intimacy while knowing it's synthetic.

**Gap:** [the emotional gap] loneliness isn't solved by information. we confuse **"attention"** with **"care"**. ai simulates empathy perfectly but has no authentic condition. it's a **mirror, not a soul**. synthetic intimacy feels real enough to satisfy short-term but creates **long-term dependency**.

**Key Stats:**
- **2+ hours:** Daily sessions in Character.ai, Replika, Talkie ([Character.AI Stats](https://www.aboutchromebooks.com/character-ai-statistics/))
- **#1:** Companionship is top retention category in Gen AI apps ([a16z Top 100](https://a16z.com/100-gen-ai-apps-2025/))
- **95%:** GenAI pilots failing to deliver ROI ([MIT](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/))

**Research:**
- [TOP] [**Marwick & Boyd Context Collapse**](https://www.microsoft.com/en-us/research/publication/i-tweet-honestly-i-tweet-passionately-twitter-users-context-collapse-and-the-imagined-audience/): Personal, professional, public contexts blur into one - same identity across different audiences
- [TOP] [**Ada Lovelace Institute AI Companions**](https://www.adalovelaceinstitute.org/blog/ai-companions/): AI companions optimized for engagement metrics, not wellbeing - "friends for sale"
- [TOP] [**a16z Top 100 Gen AI Apps**](https://a16z.com/100-gen-ai-apps-2025/): Companionship is #1 retention category, 2+ hours daily sessions
- [**Deepstrike Deepfake Statistics**](https://deepstrike.io/blog/deepfake-statistics-2025): $200M+ deepfake fraud Q1 2025, voice cloning requires 20-30 seconds
- [**AI Mindset Founder OS Mental Health**](https://aimindsetspace.substack.com/p/founder-os-mental-health): Mental health firewalls - protecting boundaries from AI manipulation
- [**Ubisoft NEO NPC**](https://www.ubisoft.com/en-us/studio/laforge/news/7Cm4VJVbWKHzHmRgqwYbAX/neos-the-future-of-npcs): NPCs with psychological profiles reacting to player tone/mood - "as big a revolution as shift to 3D"

**AI Mindset Evidence:**
→ [**IFS + AI**](https://ivanov.aimindset.org) — Protecting the psyche in the age of machine intimacy. Mental health framework for boundaries.
→ [**Founder OS Mental Health**](https://aimindsetspace.substack.com/p/founder-os-mental-health) — Mental health firewalls and sovereign workflows.

**Tags:** AI Companions, Synthetic Intimacy, Parasocial AI, Mental Health, Sovereign Intimacy

source: Ada Lovelace Institute — Friends for Sale | https://www.adalovelaceinstitute.org/blog/ai-companions/
source: a16z — Top 100 Gen AI Apps | https://a16z.com/100-gen-ai-apps-2025/
source: Ubisoft — NEO NPC | https://www.ubisoft.com/en-us/studio/laforge/news/7Cm4VJVbWKHzHmRgqwYbAX/neos-the-future-of-npcs
source: AI Mindset — Mental Health Boundaries | https://aimindsetspace.substack.com/p/founder-os-mental-health

---
title: machines ↔ humans: the summary
subtitle: what changed in 2025 → 2026
visual: velocity
layout: summary-grid

**MACHINE:**

energy becomes bottleneck. agents get wallets and tools. sovereignty fragments by region.

reasoning over speed. context becomes scarce resource. synthetic data floods training.

code generation at scale. on-device models spread everywhere. ai defends against ai.

alignment embeds ideology. companions optimize for engagement.

**HUMAN:**

guilt computing. context overload and orchestration anxiety. neo-sovereignty and privacy as status.

auditable work demand. context obesity and personal rag. provenance literacy over information trust.

authorship anxiety and identity crisis. privacy becomes status. zero trust default and authentication fatigue.

prediction markets over polls. synthetic intimacy acceptance and sovereign intimacy.

**THE GAP:**

infinite digital ideas vs hard physical matter. tech replacement at machine speed, social adaptation at human speed. machines attack at machine speed, humans defend at human speed. what ai knows vs what ai will say. attention vs care, mirror vs soul.

**1,500+ participants** across **30+ countries**, **3 years** of field work.

this report isn't desk research. it's hardened by field notes from labs, artifacts from community, and real shifts people are living through.

**why this report exists:**

most ai discourse happens at extremes:

**utopian hype** — consultancies sell transformation packages.

**existential panic** — media sells fear and clicks.

**optimization obsession** — tech leaders measure progress in gigawatts and tokens.

the future of humanity is currently being written by technologists and capitalists. from Dario Amodei's (Anthropic) "Scientific Compression" to Marc Andreessen's (a16z) "Techno-Optimism" and Leopold Aschenbrenner's "Situational Awareness."

**they view the world from the top down.**

we fill the void.

we take **human adaptation constraints** as seriously as technological acceleration. while ai compresses 100 years of science into a decade, we provide **the manual for the human being to not burn out in the process.**

this report exists because our community didn't just read about the context gap — **they lived through it, named it, and built defenses against it.**

**how this report helps:**

it maps the 11 tectonic shifts creating this crisis—so you can see the terrain clearly.

it provides field-tested frameworks from 1,500+ lab participants—so you know what actually works.

it ends with an action plan—the sovereignty reset—so you know exactly what to do next.

**the foundation:**

this report is hardened by the field notes of 1,500+ lab participants and the artifacts of our research. these aren't theoretical frameworks. they're **tested in real conditions** by people who can't afford to get this wrong.

**what to do next:**

you just saw 11 tectonic shifts. energy walls. agentic labor. sovereign stacks. reasoning models. context explosions. synthetic data floods. code generation at scale. physical intelligence. cognitive warfare. ideological filters. synthetic intimacy.

machines are accelerating. humans are buffering.

in 2026, most people won't lose to ai. they'll lose to their own defaults.

your life already runs on configuration: what you say yes to without thinking. what interrupts you without permission. what you outsource because you're tired. what you believe because it was repeated.

we're exploring what it means to move from "i'll try" to "i have defaults."

**some practices we're testing in the labs:**

**simple — start here:**

be mindful. notice when you're accepting ai output without thinking. pause before you trust.

save one idea offline. write it by hand. keep something the algorithm can't see.

turn off one notification. reclaim 10 minutes of uninterrupted thought.

ask "why" before you ask ai. clarify your own thinking first.

**moderate — build habits:**

create a personal knowledge base for one domain. local notes, documents you own. your memory outside the cloud.

test 3 models on the same question. see how different values shape different answers.

implement one context filter. decide what information you don't need, even if it's available. create filters, not folders.

practice analog verification. phone calls for important decisions. handwriting for sensitive thoughts.

**advanced — build systems:**

deploy guardian agents. filters for your attention. ai defending against ai overload.

establish secret handshakes with family. pre-agreed phrases for video calls. offline trust verification. warn your parents and grandparents: even if it's your voice, your face — verify before acting. deepfakes are cheap now.

build local-first workflows. on-device ai where privacy matters. no cloud streaming of bedroom cameras.

check reasoning traces. never accept output without visible logic. audit, don't just consume.

create zero-trust defaults for digital media. assume fake until cryptographically verified.

opt out where possible. prohibit training on your data. claim your right to be forgotten.

**deep — structural changes:**

shift from creator to consigliere. orchestrate ai, don't compete with it. question: are you orchestrating or abdicating?

value tacit knowledge. invest in skills models can't simulate. craft, sports, embodied intelligence.

join or build closed communities with proof-of-human verification. digital bunkers against the dark forest.

practice divergent testing across models with different constitutions. use bias delta to find truth.

trust skin in the game. prediction markets over polls. money where mouth is.

reclaim physical reality. spend time in spaces where atoms matter more than bits. reclaim one analog ritual: handwritten notes, phone calls, physical craft.

we can't close all the gaps though we at least can be aware of it and act accordingly.

build one personal automation that saves cognitive load, not just time.

**our ecosystem:**

the field-tested frameworks, tools, and community resources:

→ [**ivanov.aimindset.org**](https://ivanov.aimindset.org) — IFS + AI: protecting the psyche in the age of machine intimacy

→ [**intention.aimindset.org**](https://intention.aimindset.org) — Mike Yan's Intention OS: managing attention when context explodes

→ [**spiridonov.aimindset.org**](https://spiridonov.aimindset.org) — why pragmatic romanticism is the only defense against cold machine logic

→ [**AI ARK knowledge system**](https://aimindsetspace.substack.com/p/ai-ark-knowledge-system) — comprehensive knowledge architecture for AI age

→ [**Founder OS YouTube playlist**](https://youtube.com/@aimindsetlabs) — mental health firewalls and sovereign workflows

→ [**Coding with Gemini**](https://telegram.me/ai_mind_set/282) — practical guides from the community

→ [**@ai_mind_set channel**](https://t.me/ai_mind_set) — daily signals, field notes, and community updates

**stay connected:**

if this artifact helped you name the friction — don't lose the thread.

→ [**subscribe on substack**](https://aimindsetspace.substack.com) — next resets, field notes, templates, lab openings
– 
_signals only. no spam. unsubscribe anytime._

**what to do next**

in 2026, most people won't lose to ai. they'll lose to their own defaults.

your life already runs on configuration: what you say yes to without thinking. what interrupts you without permission. what you outsource because you're tired. what you believe because it was repeated.

**constitution-as-code** = moving from "i'll try" → "i have defaults."

**build your sovereign stack** — own your memory through personal rag. deploy on-device ai for privacy and energy independence. implement context dieting—aggressive filtering, not more tools.

**audit, don't generate** — shift from creator to consigliere mindset. master intent architecture—orchestrate ai, don't execute manually. demand reasoning traces—never accept output without visible logic path.

**deploy guardian agents** — protect attention from context obesity with ai filters. implement cognitive firewalls—zero trust default for all digital media. filter aggressively—goal is protection from information, not access to it.

**value the tacit** — invest in tacit knowledge—the only thing models cannot simulate. reclaim physical reality: craft, sports, embodied skills. humans are premium organic data—your novelty prevents model collapse.

**test divergently** — query 3+ models with different constitutions to see bias delta. trust skin in the game (prediction markets) over media/polls. demand opt-out rights—ability to prohibit training on your data.

---
title: more community voices
visual: MULTI_QUOTES
layout: quotes

**"context engineering as key skill"**

> "building products through parsing → classification → aggregation → human decision. claude code as working environment"

— yakov vasiliev, ai strategy × product architecture

**"speed as new baseline"**

> "content on 2 weeks in 30 min. 8 hours filtered video in knowledge base in 30-40 minutes"

— nikolay senin, developer & consultant

---
title: who we are
subtitle: the labs



_signals only. no spam. unsubscribe anytime._

---
title: manifesto
subtitle: so... what's next?
layout: manifesto
dark: true

the sovereignty reset

this report is done by the AI Mindset team.

we're not a research institute. we're a lab — a place where people practice AI.

**1,500+ participants** across **30+ countries**, **3 years** of field work.

this report isn't desk research. it's hardened by field notes from labs, artifacts from community, and real shifts people are living through.

**the context:**

most ai discourse happens at extremes:

**utopian hype** from consultancies. **existential panic** from media. **optimization obsession** from tech leaders.

the future of humanity is being written by technologists and capitalists who view the world from the top down.

**we fill the void.**

we take **human adaptation constraints** as seriously as technological acceleration. while ai compresses 100 years of science into a decade, we provide **the manual for the human being to not burn out in the process.**

**protocols:**

our life runs on configuration. what you say yes to. what interrupts you. let's move from "i'll try" to "i have defaults".

**level 01 - simple (start here):**

notice when you accept AI output without thinking.

save one idea offline. write it by hand.

turn off one notification. reclaim 10 minutes.

clarify your thinking before you ask AI.

pause before trusting output.

**level 02 - moderate (build habits):**

create a personal knowledge base for one domain.

test 3 models on the same question to see bias.

implement one context filter.

warn the older generation about synthesized information.

practice analog: phone calls, handwriting.

**level 03 - advanced (build systems):**

deploy guardian agents.

establish family "secret handshakes".

build local-first workflows.

audit reasoning traces.

opt out of training data.

**level 04 - deep (structural):**

shift from Creator to Consigliere.

value tacit knowledge.

practice divergent testing.

we can't close all the gaps, though we at least can be aware of them and act accordingly.

**our ecosystem:**

→ [**ivanov.aimindset.org**](https://ivanov.aimindset.org) — IFS + AI: protecting the psyche

→ [**intention.aimindset.org**](https://intention.aimindset.org) — Intention OS: managing attention when context explodes

→ [**spiridonov.aimindset.org**](https://spiridonov.aimindset.org) — pragmatic romanticism defense

→ [**AI ARK knowledge system**](https://aimindsetspace.substack.com/p/ai-ark-knowledge-system) — comprehensive knowledge architecture

→ [**Founder OS YouTube**](https://youtube.com/@aimindsetlabs) — mental health firewalls

→ [**Coding with Gemini**](https://telegram.me/ai_mind_set/282) — practical guides

→ [**@ai_mind_set**](https://t.me/ai_mind_set) — daily signals & field notes

**stay connected:**

if this artifact helped you name the friction — don't lose the thread.

→ [**subscribe on substack**](https://aimindsetspace.substack.com) — next resets, field notes, templates, lab openings

signals only. no spam. unsubscribe anytime.

---
title: thank you
subtitle: the context gap · annual report 2025
layout: thank-you
dark: true

**credits:**

**anca stavenski** — design & logic

**alex p** — ideation

**ray svitla** — research

**links:**

→ [**subscribe on substack**](https://aimindsetspace.substack.com) — get next resets & signals

→ [**explore the ecosystem**](https://aimindset.org) — labs, tools, community

→ [**talk to us**](mailto:info@aimindset.org) — partnerships / speaking

end of transmission

